{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "physical_device = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if len(physical_device) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_device[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "diabetes_dataset = load_diabetes()\n",
    "data = diabetes_dataset['data']\n",
    "targets = diabetes_dataset['target']\n",
    "\n",
    "train_data, test_data, train_targets, test_targets = train_test_split(data, targets, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(train_data.shape[1],)),\n",
    "    Dense(64,activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)        \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',\n",
    "                optimizer=\"adam\",metrics=[\"mse\",\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_function(epoch, lr):\n",
    "    if epoch % 2 == 0:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr + epoch/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.011000000047497452.\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.010999999940395355.\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.040999999940395354.\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.04100000113248825.\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.09100000113248825.\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.09099999815225601.\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.16099999815225602.\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.16099999845027924.\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.2509999984502792.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_targets, epochs=10,\n",
    "                    callbacks=[tf.keras.callbacks.LearningRateScheduler(lr_function, verbose=1)], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.3333333333333333.\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.125.\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.07692307692307693.\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.05555555555555555.\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.043478260869565216.\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.03571428571428571.\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.030303030303030304.\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.02631578947368421.\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.023255813953488372.\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.020833333333333332.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_targets, epochs=10,\n",
    "                    callbacks=[tf.keras.callbacks.LearningRateScheduler(lambda x:1/(3+5*x), verbose=1)], \n",
    "                    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data, train_targets, epochs=10,\n",
    "                    callbacks=[tf.keras.callbacks.CSVLogger(\"results.csv\")], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2747.347900</td>\n",
       "      <td>41.892494</td>\n",
       "      <td>2747.347900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2683.184082</td>\n",
       "      <td>41.432407</td>\n",
       "      <td>2683.184082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2771.436768</td>\n",
       "      <td>42.042202</td>\n",
       "      <td>2771.436768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2626.170166</td>\n",
       "      <td>41.073864</td>\n",
       "      <td>2626.170166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2633.089844</td>\n",
       "      <td>40.744808</td>\n",
       "      <td>2633.089844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2637.919678</td>\n",
       "      <td>40.959881</td>\n",
       "      <td>2637.919678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2700.083008</td>\n",
       "      <td>40.767708</td>\n",
       "      <td>2700.083008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2862.056885</td>\n",
       "      <td>42.766960</td>\n",
       "      <td>2862.056885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2675.962891</td>\n",
       "      <td>41.167889</td>\n",
       "      <td>2675.962891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2615.853027</td>\n",
       "      <td>40.429905</td>\n",
       "      <td>2615.853027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              loss        mae          mse\n",
       "epoch                                     \n",
       "0      2747.347900  41.892494  2747.347900\n",
       "1      2683.184082  41.432407  2683.184082\n",
       "2      2771.436768  42.042202  2771.436768\n",
       "3      2626.170166  41.073864  2626.170166\n",
       "4      2633.089844  40.744808  2633.089844\n",
       "5      2637.919678  40.959881  2637.919678\n",
       "6      2700.083008  40.767708  2700.083008\n",
       "7      2862.056885  42.766960  2862.056885\n",
       "8      2675.962891  41.167889  2675.962891\n",
       "9      2615.853027  40.429905  2615.853027"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_csv(\"results.csv\", index_col='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_callback = tf.keras.callbacks.LambdaCallback(\n",
    "    on_epoch_begin=lambda epoch,logs: print('Starting Epoch {}!'.format(epoch+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loss_callback = tf.keras.callbacks.LambdaCallback(\n",
    "    on_batch_end=lambda batch,logs: print('\\n After batch {}, the loss is {:7.2f}.'.format(batch, logs['loss'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_finish_callback = tf.keras.callbacks.LambdaCallback(\n",
    "    on_train_end=lambda logs: print('Training finished!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1!\n",
      "\n",
      " After batch 0, the loss is 3023.26.\n",
      "\n",
      " After batch 1, the loss is 2771.93.\n",
      "\n",
      " After batch 2, the loss is 2560.51.\n",
      "\n",
      " After batch 3, the loss is 2527.30.\n",
      "Starting Epoch 2!\n",
      "\n",
      " After batch 0, the loss is 2862.22.\n",
      "\n",
      " After batch 1, the loss is 2339.89.\n",
      "\n",
      " After batch 2, the loss is 2285.44.\n",
      "\n",
      " After batch 3, the loss is 2533.14.\n",
      "Starting Epoch 3!\n",
      "\n",
      " After batch 0, the loss is 2260.00.\n",
      "\n",
      " After batch 1, the loss is 2321.17.\n",
      "\n",
      " After batch 2, the loss is 2426.92.\n",
      "\n",
      " After batch 3, the loss is 2518.77.\n",
      "Starting Epoch 4!\n",
      "\n",
      " After batch 0, the loss is 2457.01.\n",
      "\n",
      " After batch 1, the loss is 2683.35.\n",
      "\n",
      " After batch 2, the loss is 2502.34.\n",
      "\n",
      " After batch 3, the loss is 2499.93.\n",
      "Starting Epoch 5!\n",
      "\n",
      " After batch 0, the loss is 2478.32.\n",
      "\n",
      " After batch 1, the loss is 2434.90.\n",
      "\n",
      " After batch 2, the loss is 2560.80.\n",
      "\n",
      " After batch 3, the loss is 2494.28.\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_targets, epochs=5, batch_size=100,\n",
    "                    callbacks=[epoch_callback, batch_loss_callback,train_finish_callback], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
